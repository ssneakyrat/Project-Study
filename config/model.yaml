# Model hyperparameters
model:
  wavelet: 'db4'     # Wavelet type
  levels: 4          # Reduced from 6 to 4 wavelet decomposition levels
  hidden_dim: 64     # Reduced from 128 to 64
  latent_dim: 256    # Latent dimension (unchanged)
  
# Training hyperparameters
training:
  batch_size: 32
  learning_rate: 0.001
  weight_decay: 0.0001  # Increased slightly for better regularization
  max_epochs: 100
  gradient_clip_val: 1.0
  
# Loss hyperparameters
loss:
  wavelet_loss_weight: 0.7
  time_loss_weight: 0.3
  loss_alpha: 0.5    # Weight increment factor for multi-scale loss
  
# Data hyperparameters
data:
  sample_rate: 16000
  duration: 2.0      # Duration in seconds
  num_workers: 4
  
# Mixed precision training
precision: 16        # Use FP16 for faster training
  
# Logging
logging:
  log_every_n_steps: 50
  logs_dir: 'logs'   # Directory for TensorBoard logs
  viz_every_n_epochs: 5  # Visualize validation samples every n epochs
  viz_num_samples: 1     # Number of samples to visualize

# Data generation parameters
data_generation:
  output_dir: 'data'
  num_samples: 1000
  sample_rate: 16000
  duration: 2.0
  split: [0.8, 0.1, 0.1]  # Train/val/test split

# Seed for reproducibility
seed: 42