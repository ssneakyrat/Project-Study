# General parameters
model_name: "wst_complex_autoencoder"
seed: 42
output_dir: "./logs"

# Data parameters
data:
  sample_rate: 16000
  audio_length: 2.0  # in seconds
  hop_length: 256
  n_fft: 1024
  cache_size: 100  # Number of samples to cache in memory

# Wavelet Scattering Transform parameters
wavelet:
  J: 6          # Number of scales - AFFECTS KYMATIO OUTPUT CHANNELS
  Q: 16         # Number of wavelets per octave - AFFECTS KYMATIO OUTPUT CHANNELS
  T: 16384      # Temporal support (must be power of 2)
  ensure_output_dim: true
  max_order: 1  # Use only first-order scattering - AFFECTS KYMATIO OUTPUT CHANNELS
  normalize: true
  
# Model architecture
model:
  latent_dim: 512
  channels: [24, 48, 96, 192]
  kernel_sizes: [7, 5, 5, 5]
  strides: [1, 2, 2, 2]
  paddings: [3, 2, 2, 2]
  output_paddings: [0, 1, 1, 1]
  dropout: 0.1
  use_batch_norm: true
  complex_repr: "mag_phase"  # Output representation mode
  use_gradient_checkpointing: true  # Memory optimization

# Training parameters
training:
  batch_size: 16
  accumulate_grad_batches: 16
  max_epochs: 100
  lr: 0.0003
  beta1: 0.5
  beta2: 0.999
  scheduler_gamma: 0.97
  num_workers: 4
  precision: 16-mixed
  gradient_clip_val: 0.5

# Loss weights
loss:
  l1_weight: 1.0
  stft_weight: 1.5
  complex_loss_weight: 0.7
  spectral_convergence_weight: 0.8
  phase_consistency_weight: 1.0