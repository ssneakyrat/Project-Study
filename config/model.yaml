# General parameters
model_name: "wst_complex_autoencoder"
seed: 42
output_dir: "./logs"

# Data parameters
data:
  sample_rate: 16000
  audio_length: 2.0  # in seconds
  hop_length: 256
  n_fft: 1024
  n_mels: 80
  cache_size: 100  # Number of samples to cache in memory

# Wavelet Scattering Transform parameters
wavelet:
  J: 4  # Reduced from 4 16x temporal downsampling
  Q: 8  # Number of wavelets per octave
  T: 8192  # Temporal support of the lowpass filter
  ensure_output_dim: true  # New flag to enforce dimension matching
  
# Model architecture
model:
  latent_dim: 128
  channels: [32, 64, 128, 256]
  kernel_sizes: [5, 5, 5, 5]  # Symmetric kernels for better reconstruction
  strides: [2, 2, 2, 2]
  paddings: [2, 2, 2, 2]  # Explicit padding control
  output_paddings: [1, 1, 1, 1]  # For transposed convolutions
  dropout: 0.1
  use_batch_norm: true
  complex_repr: "rectangular"  # rectangular or polar

# Training parameters
training:
  batch_size: 16
  accumulate_grad_batches: 2
  max_epochs: 100
  lr: 0.0002
  beta1: 0.5
  beta2: 0.999
  scheduler_gamma: 0.95
  num_workers: 4
  precision: 16-mixed  # Use mixed precision

# Loss weights
loss:
  l1_weight: 1.0  # Increased from 0.5
  stft_weight: 1.0
  complex_loss_weight: 0.25
  spectral_convergence_weight: 0.5