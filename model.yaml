# Model Configuration
model:
  input_shape: [862, 80]
  output_shape: [22050]
  encoder_filters: [32, 64, 128, 256]
  decoder_filters: [64, 32, 16, 8]
  bottleneck_size: 512
  dropout_rate: 0.2
  
# Training Configuration
training:
  batch_size: 32
  epochs: 100
  learning_rate: 0.001
  lr_scheduler: true
  lr_factor: 0.5
  lr_patience: 10
  weight_decay: 0.00001 #1e-5
  grad_clip_val: 1.0
  grad_accumulation_steps: 1
  mixed_precision: true

# Data Configuration
data:
  data_file: "signal_data.h5"
  train_val_split: 0.8
  num_workers: 4
  persistent_workers: true
  prefetch_factor: 2
  log_scale_normalize: true

# Logging Configuration
logging:
  log_every_n_steps: 10
  log_val_every_epoch: 10
  tensorboard_log_dir: "logs"
  save_model_dir: "logs/checkpoints"
  save_every_n_epochs: 10  # Save checkpoint every 10 epochs
  save_best_models: false  # Set to false to disable validation loss checkpoints
  save_best_models_count: 3  # How many best models to save